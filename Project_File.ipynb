{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIA-660 Web Mining Project\n",
    "## Project Title - Movie Recommendation System\n",
    "### Objective:\n",
    "We aim to build a movie recommendation system wherein we will understand the users watch history and recommend movies accordingly. Instead of asking users choice of preference we will extract this information from their watching history.\n",
    "#### Dataset for our project will be collected from website: https://www.allmovie.com\n",
    "![alt text](https://upload.wikimedia.org/wikipedia/commons/c/c7/Allmovie_Logo.png \"Logo Title Text 1\")\n",
    "This website provide comprehensive movie information including reviews, ratings, biographies etc. We will be looking into more granular data while scraping the data set. Apart from genres, we will be considering keywords, themes, reviews which will be used for multilevel scraping for more accurate prediction.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-1: Scraping genres names and its link\n",
    "* Find element through css selector using BeautifulSoup\n",
    "* Fetch the name and its corresponding href link and store it in the dictionary\n",
    "* Iterate through the dictionary items and store in the .csv file (genres.csv)\n",
    "* Git Link: [genres.csv](https://github.com/athiban94/movie-recommendation/blob/master/genres.csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "headers = { 'user-agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/46.0.2490.'\n",
    "                          '86 Safari/537.36'}\n",
    "\n",
    "# site url\n",
    "siteURL = \"https://www.allmovie.com\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # send a get request to the web page\n",
    "    page = requests.get(\"https://www.allmovie.com/genres\", headers=headers)\n",
    "\n",
    "    if page.status_code == 200:\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "        # Creating a dictionary to store the genre name as \"key\" and link as \"value\"\n",
    "        genres = {}\n",
    "\n",
    "        genreList = soup.select(\"div.genres div.genre h3 a\")\n",
    "        for genre in genreList:\n",
    "            genres[genre.text] = siteURL + genre['href']\n",
    "\n",
    "        with open('genres.csv', 'w', newline='') as f:\n",
    "            writer = csv.writer(f, delimiter=',')\n",
    "            writer.writerow(['Genre', 'link'])\n",
    "            for key, value in genres.items():\n",
    "                writer.writerow([key, value])\n",
    "\n",
    "    else:\n",
    "        print(\"Oops! could not get page, Error: \",page.status_code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-2 Scraping all movies and its link from each of the category url\n",
    "* Read genres.csv, fetch category and links column and convert it to dictionary\n",
    "* Iterate the above dictionary result to fetch all the individual movies within the particular genre.\n",
    "* Handle pagenation senario wherein a particular genre may have n-number of pages.\n",
    "* Store the output output in the .csv file with coloumns - [category], [movie-name], [movie-href-url]\n",
    "* Generated File name: categoryMovieLinksList.csv\n",
    "* Git Link: \n",
    "[categoryMovieLinksList.csv](https://github.com/athiban94/movie-recommendation/blob/master/categoryMovieLinksList.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "headers = { 'user-agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/46.0.2490.'\n",
    "                          '86 Safari/537.36'}\n",
    "\n",
    "# site url\n",
    "siteURL = \"https://www.allmovie.com\"\n",
    "movieCorpusList = []\n",
    "def scrapePageContents(category, categoryLink):\n",
    "    print(categoryLink)\n",
    "    page = requests.get(categoryLink, headers=headers)\n",
    "    if page.status_code == 200:\n",
    "        print(\"succes\")\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        pagenationNext = soup.select('div.pagination span.next a')\n",
    "\n",
    "        moviesList = soup.select(\"div.movie-highlights div.movie_row div.movie p.title a\")\n",
    "        for movie in moviesList:\n",
    "            movieTuple = (category, movie.text.strip(), siteURL + movie[\"href\"])\n",
    "            movieCorpusList.append(movieTuple)\n",
    "        if(pagenationNext):\n",
    "            for page in pagenationNext:\n",
    "                url = siteURL + page[\"href\"]\n",
    "                scrapePageContents(category, url)\n",
    "        else:\n",
    "            print(\"End of category: \" + category)\n",
    "\n",
    "def generateMovieCateoryTuples(categoryList):\n",
    "    for category, categoryLink in categoryList.items():\n",
    "        scrapePageContents(category, categoryLink)\n",
    "\n",
    "    for element in movieCorpusList:\n",
    "        print(element)\n",
    "    return movieCorpusList\n",
    "\n",
    "def saveMoviesInCSV(movieCorpusList):\n",
    "    with open('categoryMovieLinksList.csv', 'w') as f:\n",
    "        writer = csv.writer(f, lineterminator='\\n')\n",
    "        for tup in movieCorpusList:\n",
    "            writer.writerow(tup)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = pd.read_csv(\"genres.csv\", header=0)\n",
    "    categoryList = dict(zip(data[\"Genre\"].values.tolist(), data[\"link\"].values.tolist()))\n",
    "    entireMovieList = generateMovieCateoryTuples(categoryList)\n",
    "    saveMoviesInCSV(entireMovieList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-3 Scrap all movie contents with movie links\n",
    "* Read categoryMovieLinksList.csv file fetching all movie links from the column\n",
    "* Iterate each movie links to get values category, movie, title, rating, genre, subgenre, theme, keyword, releasedate, country, review\n",
    "* Store the entire the data to the movie10k.csv file\n",
    "* Check for duplicate rows and remove it\n",
    "* Link: [movie10k.csv](https://github.com/athiban94/movie-recommendation/blob/master/movie10k.csv)\n",
    "* Link for sample data set:[movie1k.csv]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import requests                   \n",
    "from bs4 import BeautifulSoup \n",
    "import csv\n",
    "import re\n",
    "\n",
    "def extract_source(url):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:50.0) Gecko/20100101 Firefox/50.0'}\n",
    "    source=requests.get(url, headers=headers).text\n",
    "    return source\n",
    "\n",
    "def extract_data(source,category=\"\",mvname=\"\"):\n",
    "    \n",
    "    mvdata=dict.fromkeys([\"category\",\"movie\",\"title\",\"rating\",\"genre\",\"subgenre\",\"theme\",\"keyword\",\"releasedate\",\"country\",\"review\"],\"\")\n",
    "    #print(mvdata)\n",
    "    mvdata[\"category\"]=category\n",
    "    mvdata[\"movie\"]=mvname\n",
    "    \n",
    "    soup=BeautifulSoup(source, 'html.parser')\n",
    "    \n",
    "    #Title\n",
    "    names=soup.find('meta',property =\"og:title\" )\n",
    "    title=names[\"content\"] if names else \"No meta title given\"\n",
    "    mvdata[\"title\"]=title.split(\"-\")[0].strip()\n",
    "    #print(title)\n",
    "    \n",
    "    #Rating\n",
    "    rating_par = soup.findAll('div', attrs={'itemprop':'ratingValue'})\n",
    "    if(rating_par!=None and len(rating_par)>0):\n",
    "        rating=rating_par[0].text.strip()\n",
    "        mvdata[\"rating\"]=rating\n",
    "        #print(rating)\n",
    "    \n",
    "    #Genre\n",
    "    genre_par = soup.findAll(\"span\", class_=\"header-movie-genres\")\n",
    "    gtext= genre_par[0].findAll(\"a\",href=True)\n",
    "    genre=gtext[0].text\n",
    "    mvdata[\"genre\"]=genre\n",
    "    #print(genre)\n",
    "    \n",
    "    #Sub_Genre\n",
    "    sub_genre_par = soup.findAll(\"span\", class_=\"header-movie-subgenres\")\n",
    "    if(sub_genre_par!=None and len(sub_genre_par)>0):\n",
    "        stext = sub_genre_par[0].findAll(\"a\",href=True)\n",
    "        if(stext!=None and len(stext)>0):\n",
    "            sub_genre=stext[0].text\n",
    "            mvdata[\"subgenre\"]=sub_genre\n",
    "            #print(sub_genre)\n",
    "    \n",
    "    #Theme\n",
    "    theme_str = \"\"\n",
    "    theme = soup.findAll(\"div\",class_=\"charactList\")\n",
    "    if(theme!=None and len(theme)>0):\n",
    "        ttext = theme[0].findAll(\"a\",href=True)\n",
    "        for themes in ttext:\n",
    "            theme_str=themes.text+\",\"+theme_str\n",
    "        theme_str=theme_str.strip(\",\")\n",
    "        mvdata[\"theme\"]=theme_str\n",
    "        #print(theme_str)\n",
    "    \n",
    "    #Keyword\n",
    "    keyword_par = soup.findAll(\"div\",class_=\"keywords\")\n",
    "    if(keyword_par!=None and len(keyword_par)>0):\n",
    "        keywords=keyword_par[0].findAll(\"div\",class_=\"charactList\")[0].text.strip()\n",
    "        #keywords=keyword_par[0]\n",
    "        mvdata[\"keyword\"]=keywords\n",
    "    #print(keywords)\n",
    "    \n",
    "    #Details\n",
    "    #date of release\n",
    "    detail = soup.findAll(\"hgroup\",class_=\"details\")\n",
    "    for det in detail[0].findAll(\"span\"):\n",
    "        #print( det.text.split(\"-\")[0].strip(\" \\n\"))\n",
    "        if det.text.split(\"-\")[0].strip()==\"Release Date\":\n",
    "            rel_dte = det.text.split(\"-\")[1].split(\"(\")[0].strip()\n",
    "            mvdata[\"releasedate\"]=rel_dte\n",
    "            #print(rel_dte)\n",
    "    \n",
    "            #Countries of Release\\\n",
    "        if det.text.split(\"-\")[0].strip()==\"Countries\":\n",
    "            cntry=det.text.split(\"-\")[1].strip().strip(\"|\\xa0\")\n",
    "            mvdata[\"country\"]=cntry\n",
    "            #print(cntry)\n",
    "    \n",
    "    #Review\n",
    "    review_par = soup.findAll(\"div\",itemprop = \"description\")\n",
    "    if(review_par!=None and len(review_par)>0):\n",
    "        review=review_par[0].text.strip()\n",
    "        mvdata[\"review\"]=review\n",
    "        #print(review)\n",
    "    \n",
    "    return mvdata\n",
    "\n",
    "url_str1 = 'https://www.allmovie.com/movie/a-star-is-born-v548181'\n",
    "url_str2 = 'https://www.allmovie.com/movie/the-revenant-v597171'\n",
    "\n",
    "print(extract_data(extract_source(url_str2)))\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with open('movie10k.csv', 'w', newline = '') as f:  # Just use 'w' mode in 3.x\n",
    "        with open('categoryMovieLinksList.csv') as csv_file:\n",
    "            csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "            cnt=0\n",
    "            seen = set()\n",
    "            for row in csv_reader:\n",
    "                if cnt<11000:\n",
    "                    print(row)\n",
    "                    if row[1].strip() not in seen: \n",
    "                        seen.add(row[1].strip())\n",
    "                        mvdict=extract_data(extract_source(row[2]),row[0],row[1])\n",
    "                        w = csv.writer(f)\n",
    "                        #w.writeheader()\n",
    "                        if cnt==0:\n",
    "                            w.writerow(mvdict.keys())\n",
    "                        w.writerow(mvdict.values())\n",
    "                    else:\n",
    "                        print(\"Duplicate:::::: \",row[1].strip())\n",
    "                    cnt=cnt+1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step - 4 EDA - Analysis\n",
    "* Read the movies10k.csv file and fetch the keywords and themes column\n",
    "* Performed tokenization of keywords and themes of each category\n",
    "* Generated tf-idf matrix for the same\n",
    "* Performed lemmatization and removed stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print top keywords by category:\n",
      "{'Action': ['Superhero', 'revenge', 'martial-arts'], 'Adult': ['sex', 'bachelorette', 'eroticism'], 'Adventure': ['villain', 'rescue', 'pirate [seafarer]'], 'Avant-garde / Experimental': ['experimental  [arts]', 'filmmaker', 'homosexual'], \"Children's/Family\": ['friendship', 'animal', 'dog'], 'Comedy': ['love', 'romance', 'friendship'], 'Comedy Drama': ['love', 'friendship', 'romance'], 'Crime': ['gangster', 'organized-crime', 'mob-boss'], 'Drama': ['love', 'family', 'friendship'], 'Epic': ['battle [war]', 'war', 'emperor'], 'Fantasy': ['afterlife', 'love', 'magic'], 'Historical Film': ['war', 'aristocracy', 'king'], 'Horror': ['vampire', 'murder', 'mad-scientist'], 'Musical': ['love', 'performer', 'songwriter'], 'Mystery': ['murder', 'investigation', 'kill'], 'Romance': ['love', 'romance', 'extramarital-affair'], 'Science Fiction': ['alien [not human]', 'future', 'spacecraft'], 'Spy Film': ['espionage', 'agent [representative]', 'spy'], 'Thriller': ['murder', 'kill', 'psychopath'], 'War': ['war', 'soldier', 'military'], 'Western': ['outlaw [Western]', 'cowboy', 'bad-guy']}\n",
      "print top themes by category:\n",
      "{'Action': ['Adrenaline Rush', 'Tough Guys', 'Nail-biters'], 'Adult': ['Sexual Awakening', 'Dangerous Attraction', 'Carnal Knowledge'], 'Adventure': ['Adrenaline Rush', 'Tough Guys', 'Pick-Me-Ups'], 'Avant-garde / Experimental': ['Head Trips', 'Food for Thought', 'Off the Beaten Path'], \"Children's/Family\": ['Young and Old Alike', 'Pick-Me-Ups', 'Fantastic Reality'], 'Comedy': ['Just for Fun', 'Comedy on the Edge', 'Pick-Me-Ups'], 'Comedy Drama': ['Only Human', 'Comedy on the Edge', 'Strictly Speaking'], 'Crime': ['Tough Guys', 'Nail-biters', 'In a Minor Key'], 'Drama': ['Only Human', 'In a Minor Key', 'Food for Thought'], 'Epic': ['For Love of Country', 'Triumph of the Spirit', 'Great Battles'], 'Fantasy': ['Fantastic Reality', 'Other Dimensions', 'In the Mood for Love'], 'Historical Film': ['Crowned Heads', 'For Love of Country', 'Political Unrest'], 'Horror': ['Blood and Gore', 'Nail-biters', 'Spellbinders'], 'Musical': ['Pick-Me-Ups', \"Musician's Life\", 'In the Mood for Love'], 'Mystery': ['Spellbinders', 'Nail-biters', 'Head Trips'], 'Romance': ['In the Mood for Love', 'A Good Cry', 'Only Human'], 'Science Fiction': ['Other Dimensions', 'Fantastic Reality', 'Adrenaline Rush'], 'Spy Film': ['Traitorous Spies/Double Agents', 'Nail-biters', 'Assassination Plots'], 'Thriller': ['Nail-biters', 'Spellbinders', 'Head Trips'], 'War': ['For Love of Country', 'Military Life', 'Life Under Occupation'], 'Western': ['Tough Guys', 'Sheriffs and Outlaws', 'Ranchers']}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.spatial import distance\n",
    "\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "\n",
    "def get_wordnet_pos(pos_tag):\n",
    "    if pos_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif pos_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif pos_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif pos_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "#adding new stopwords based upon domain knowledge\n",
    "stop_words.append('nan')\n",
    "\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def tokenize(keywords):\n",
    "    token_count={}\n",
    "    tokens=[x.strip() for x in keywords.split(\",\")]\n",
    "    #print(tokens)\n",
    "    tag_token=nltk.pos_tag(tokens)\n",
    "    #print(tag_token)\n",
    "    lem_tok=[]\n",
    "    for (w,tag) in tag_token:\n",
    "        if w not in stop_words:\n",
    "            lem_tok.append(wordnet_lemmatizer.lemmatize(w, get_wordnet_pos(tag)))\n",
    "    #print(lem_tok)\n",
    "    \n",
    "    token_count=nltk.FreqDist(lem_tok)\n",
    "        \n",
    "    return token_count\n",
    "\n",
    "\n",
    "# In[19]:\n",
    "\n",
    "\n",
    "def get_top_words(mvdata,n):\n",
    "    \n",
    "    topwrds_dict={}\n",
    "    labels=list(mvdata.keys())\n",
    "    \n",
    "    doc_dict={}\n",
    "    for lb in mvdata.keys():\n",
    "        doc_dict[lb]=tokenize(mvdata[lb])\n",
    "    \n",
    "    #calculate tfidf matrix\n",
    "    \n",
    "    #create matrix from dictionary\n",
    "    dtm=pd.DataFrame.from_dict(doc_dict,orient=\"index\")\n",
    "    dtm=dtm.fillna(0)\n",
    "    \n",
    "    #get normalized term frequency (tf) matrix        \n",
    "    tf=dtm.values\n",
    "    doc_len=tf.sum(axis=1)\n",
    "    tf=np.divide(tf.T, doc_len).T\n",
    "    \n",
    "    #get idf\n",
    "    df=np.where(tf>0,1,0)\n",
    "    idf=np.log(np.divide(len(mvdata.values()),np.sum(df, axis=0)))+1\n",
    "    \n",
    "    #tfidf\n",
    "    tfidf=normalize(tf*idf)\n",
    "    #print(tfidf)\n",
    "    \n",
    "    smoothed_idf=np.log(np.divide(len(mvdata.values())+1, np.sum(df, axis=0)+1))+1\n",
    "    #print(smoothed_idf)\n",
    "    smoothed_tf_idf=normalize(tf*smoothed_idf)\n",
    "    #print(smoothed_tf_idf)\n",
    "    \n",
    "    top=smoothed_tf_idf.argsort()[:,::-1][:,0:n]\n",
    "    #print(top)\n",
    "    for idd,row in enumerate(top):\n",
    "        topwrds_dict[labels[idd]]=[dtm.columns[x] for x in row]\n",
    "        \n",
    "    return topwrds_dict\n",
    "\n",
    "\n",
    "# In[20]:\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mvdf = pd.read_csv(\"movie10k.csv\", header =0,encoding=\"ISO-8859-1\")\n",
    "    mvkeydict={}\n",
    "    mvthemedict={}\n",
    "    for index, row in mvdf.iterrows():\n",
    "        label=row[\"category\"]\n",
    "        if label in mvkeydict.keys():\n",
    "            mvkeydict[label]=mvkeydict[label]+\",\"+str(row[\"keyword\"])\n",
    "        else:\n",
    "            mvkeydict[label]=str(row[\"keyword\"])\n",
    "        if label in mvthemedict.keys():\n",
    "            mvthemedict[label]=mvthemedict[label]+\",\"+str(row[\"theme\"])\n",
    "        else:\n",
    "            mvthemedict[label]=str(row[\"theme\"])   \n",
    "\n",
    "    #print top n keywords by category\n",
    "    print(\"print top keywords by category:\")\n",
    "    print(get_top_words(mvkeydict,3))\n",
    "\n",
    "    #print top n themes by category\n",
    "    print(\"print top themes by category:\")\n",
    "    print(get_top_words(mvthemedict,3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
